{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import rasterio \n",
    "import xarray as xr\n",
    "import rioxarray \n",
    "from mesma.core import mesma, hard_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d2dce8-3131-4bdf-beca-3cb5339c6f94",
   "metadata": {},
   "source": [
    "MESMA requires two inputs: \n",
    "\n",
    "1) a SLI consisting of class labels and corresponding spectra, and \n",
    "2) an image with the same number of bands as the SLI.\n",
    "\n",
    "Both inputs need to have the same band setting and must be in units of Reflectance [-]. \n",
    "\n",
    "The following cell contains helper functions that may be used to prepare an image and a SLI accordingly:\n",
    "* Mask band regions that should not be used for unmixing (e.g., water vapor regions)\n",
    "* Scale reflectance ro range 0..1 if necessary\n",
    "* Replace pixels containing Reflectance [-] values < 0 or > 1 in any band with a no data value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d0f2d-3c45-4863-bead-64bcc569d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_mask(wavelengths, mask_regions=[[1300,1500],[1800,2000]]):\n",
    "    \"\"\"\n",
    "    Create a band mask for provided wavelength regions (default: water vapor regions at 1300-1500 nm and 1800-2000 nm.\n",
    "    \n",
    "    :param wavelengths: np.array of wavelengths\n",
    "    :param bad_regions: list of lists containing the boundaries of the mask regions (default: [[1300,1500],[1800,2000]])\n",
    "    :return: binary band mask (good bands are True, bad bands are False)\n",
    "    \"\"\"\n",
    "    good_bands_mask = np.ones(wavelengths.shape, dtype=bool)\n",
    "    for region in mask_regions:\n",
    "        good_bands_mask = good_bands_mask * ~((wavelengths >= region[0]) & (wavelengths <= region[1]))\n",
    "        \n",
    "    return good_bands_mask\n",
    "\n",
    "\n",
    "def prepare_image(fpath, \n",
    "                  mask_regions=[[300,416],[1300,1500],[1790,2000],[2400,2600]], \n",
    "                  scale_factor=10000, \n",
    "                  min_val=0, \n",
    "                  max_val=10000, \n",
    "                  no_data_pixels=-9999):\n",
    "    \"\"\"\n",
    "    Prepare an image for MESMA.\n",
    "    * Mask band regions that should not be used for unmixing\n",
    "    * Scale Reflectance to range 0..1 if necessary\n",
    "    * Replace pixels containing Reflectance [-] < 0 or > 1 in any band with a no_data value\n",
    "    \n",
    "    :param fpath: filepath to image\n",
    "    :param mask regions: bad wavelength regions that should not be used for unmixing (default: wavelengths < 400 nm, water vapor bands at 1300-1500 nm and 1790-2000 nm, and wavelengths > 2400 nm)\n",
    "    :param scale_factor: scale factor of reflectance data (MESMA requires values to be in range 0..1, default: 10000)\n",
    "    :param min_val: lower boundary of accepted reflectance values, all values <= min_val will be set to no_data_pixels (default: 0)\n",
    "    :param max_val: upper boundary of accepted reflectance values, all values > max_val will be set to no_data_pixels (default: 10000)\n",
    "    :param no_data_pixels: value indicating no_data_pixels in MESMA (default: -9999)\n",
    "    :return: 3D xarray.DataArray of shape (bands, spatial_x, spatial_y) with reflectance scales to range 0..1 and bands cropped to good wavelength regions\n",
    "    \"\"\"\n",
    "    img = rioxarray.open_rasterio(fpath)\n",
    "    img = img[band_mask(img.wavelength, mask_regions)] \n",
    "    return xr.where((img.min(dim='band')<=min_val) | (img.max(dim='band')>max_val), no_data_pixels*scale_factor, img).T / scale_factor   \n",
    "\n",
    "\n",
    "def prepare_sli(fpath, mask_regions=[[300,416],[1300,1500],[1790,2000],[2400,2600]], scale_factor=1, num_bands=428):\n",
    "    \"\"\"\n",
    "    Prepare a spectral library for MESMA.\n",
    "    * Mask band regions that should not be used for unmixing\n",
    "    * Scale Reflectance to range 0..1 if necessary\n",
    "    \n",
    "    :param fpath: filepath to SLI\n",
    "    :param mask regions: bad wavelength regions that should not be used for unmixing (default: wavelengths < 400 nm, water vapor bands at 1300-1500 nm and 1790-2000 nm, and wavelengths > 2400 nm)\n",
    "    :param scale_factor: scale factor of reflectance data (MESMA requires values to be in range 0..1, default: 10000)\n",
    "    :param num_bands: number of bands in SLI\n",
    "    :return: two np.arrays:\n",
    "        (1) 1D np.array of strings, a class for each endmember in the library \n",
    "        (2) 2D np.array of floats and shape (bands, endmembers) with reflectance scaled to range 0..1 and bands cropped to good wavelength regions\n",
    "    \"\"\"\n",
    "    sli = pd.read_csv(fpath)\n",
    "    class_list = sli.MaterialClass.values\n",
    "    em_spectra = sli[sli.columns[-num_bands:][band_mask(sli.columns[-num_bands:].astype(float), mask_regions)]] / scale_factor\n",
    "    \n",
    "    return class_list, em_spectra.T\n",
    "\n",
    "\n",
    "def save_to_disk(arr, source_filepath, output_filepath):\n",
    "    \"\"\"\n",
    "    Save an array as a GeoTIFF using the profile of another raster.\n",
    "    \n",
    "    :param arr: np.array to save to disk\n",
    "    :param source_filepath: filepath to file to use profile from\n",
    "    :param output_filepath: filepath of new file based on profile of source_filepath containing array\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dummy = rioxarray.open_rasterio(source_filepath)\n",
    "    # read image profile (ENVI header data)\n",
    "    profile = dummy.rio._manager.acquire().profile\n",
    "    # update profile\n",
    "    profile[\"dtype\"] = 'float64'\n",
    "    profile[\"driver\"] = 'GTiff'\n",
    "    profile['interleave']='pixel'\n",
    "    profile[\"count\"] = arr.shape[0]\n",
    "    # use rasterio to write file to disk\n",
    "    with rasterio.open(output_filepath, \"w\", **profile) as dst:\n",
    "        dst.write(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa8fb0-dc36-4e7b-9ca7-491db375f9e0",
   "metadata": {},
   "source": [
    "First, the input image and SLI are prepared using the helper functions defines above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8f9bc-2bd2-4a80-b63b-b209c8da328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"path to folder that contains the image to unmix\"\n",
    "img_name = \"filename of image to unmix\"\n",
    "\n",
    "img = prepare_image(fpath=img_folder+img_name)\n",
    "class_list, em_spectra = prepare_sli(fpath=\"path to spectral library (e.g., Tanager_SLI.csv) as provided in the GitHub repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bff32-8c1c-4ac5-8cca-508b937c68ac",
   "metadata": {},
   "source": [
    "Then, an object of class MesmaModels is created using the MesmaModels() function from the mesma module. Then a look-up-table for all levels of complexity (by default 2-EM and 3-EM) is generated using the setup() function with the class list (np.array of type str) as input. The levels of complexity to be used for MESMA can be controlled with the select_level() function. By default MESMA runs 2-EM and 3-EM models but it is also possible to use either one of these and higher levels of complexity cane be initiated as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5ab70-6d37-4326-b971-9318764ff3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_models = mesma.MesmaModels()\n",
    "em_models.setup(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34a2cc-bc52-4e22-9da9-a759564a487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines control the class levels in MESMA using the 'state' parameter.\n",
    "# Per default MESMA runs 2-EM and 3-EM models (state=True for levels 2 and 3) but it is also possible to only run 2-EM models (state=True only for level 2)\n",
    "# or only 3-EM models (state = True only for level 3). \n",
    "# We use this code to add 4-EM models. If you want to run 2-EM, 3-EM, and 4-EM models set state = True for all levels.\n",
    "# The code part of the setup() function in the class 'MesmaModels' (https://mesma.readthedocs.io/en/latest/_modules/mesma/core/mesma.html#MesmaModels.setup).\n",
    "\n",
    "em_models.select_level(state=True, level=2)\n",
    "em_models.select_level(state=True, level=3)\n",
    "em_models.select_level(state=False, level=4)\n",
    "\n",
    "for i in np.arange(em_models.n_classes):\n",
    "    em_models.select_class(state=True, index=i, level=2)\n",
    "    em_models.select_class(state=True, index=i, level=3)\n",
    "    em_models.select_class(state=False, index=i, level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619458a9-979e-4a11-8878-b96dfa28b063",
   "metadata": {},
   "source": [
    "To run MESMA, we create an object of class MesmaCore using the MesmaCore() function from the mesma module in the core subpackage, and use the n_cores parameter to define the number of cores dedicated to the process. Note that parallel processing is implemented through a split of the look-up-table into n parts defined by the n_cores parameter. For each subset of the look-up-table, a separate MESMA instance will be created. Finally, MESMA is executed using the execute() function of the MesmaCore object.\n",
    "\n",
    "Because the data stored in memory can be very extensive, we split up the image into chunks and then loop over the chunks and run MESMA for each chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0790b-2caa-47ff-8e1c-0c36d520082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# Arrays to fill with chunks during for-loop\n",
    "out_models = np.zeros((len(np.unique(class_list)), img.shape[1], img.shape[2])) * np.nan \n",
    "out_fractions = np.zeros((len(np.unique(class_list)) + 1, img.shape[1], img.shape[2])) * np.nan # + 1 for the shade fraction\n",
    "out_rmse = np.zeros((img.shape[1], img.shape[2])) * np.nan\n",
    "out_residuals = np.zeros((img.shape)) * np.nan\n",
    "# list to store all MESMA information for each chunk\n",
    "out_dicts = []\n",
    "\n",
    "total_start = timeit.default_timer()\n",
    "\n",
    "start_row = 0\n",
    "split_size = 10 # number of rows per chunk to be unmixed\n",
    "\n",
    "for chunk in range(start_row, img.shape[1], split_size):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # Create MESMA object.\n",
    "    MESMA = mesma.MesmaCore(n_cores=8) # number of cores for parallel processing; the look-up-table of endmember combinations is split into n parts used for parallel unmixing, several image copies are stored in memory during unmixing.\n",
    "\n",
    "    # Execute MESMA.\n",
    "    models, fractions, rmse, residuals = MESMA.execute(image = img[:, start_row:start_row+split_size, :].data, # image to be unmixed as np.array with shape (spatial_x, spatial_y, bands), needs to have same band setting as library and reflectance values ranging 0..1.\n",
    "                                            library = em_spectra, # endmember spectra as 2D np.array (spectra as columns), needs to have same band setting as image and reflectance values ranging 0..1.               \n",
    "                                            look_up_table = em_models.return_look_up_table(), # all endmember combinations (=models) for MESMA; ordered per complexity level and perclass-model; n_models x n_endmembers\n",
    "                                            em_per_class = em_models.em_per_class, # a list of all library indices per endmember class\n",
    "                                            constraints = (-0.05, 1.05, -0.1, 0.8, 0.05, -9999, -9999), # min + max endmember fraction, min + max shade fraction, max rmse, residual reflectance threshold + max number of consecutive bands exceeding threshold. set value to -9999 if not used, default: (-0.05, 1.05, 0., 0.8, 0.025, -9999, -9999)\n",
    "                                            no_data_pixels = np.where(img[0, start_row:start_row+split_size, :].data==-9999), # indices of pixels that contain no data (result of np.where), -9999 for GAO data\n",
    "                                            shade_spectrum = None, # single spectrum of photometric shade: default: None\n",
    "                                            fusion_value = 0.01, # only select a model of higher complexity (e.g. 3-EM over 2-EM) of the RMSE is better with at least this value, default: 0.007\n",
    "                                            residual_image = True, # output the residuals as an image (ignored when using band weighing or -selection), default: False\n",
    "                                            use_band_weighing = False, # use the weighted linear spectral mixture analysis (Somers et al, 2009), default: False\n",
    "                                            use_band_selection = False, # use the bands selection algorithm (Somers et al, 2010), default: False\n",
    "                                            bands_selection_values = (0.99, 0.01) # correlation threshold and decrease for the band selection algorithm, default: (0.99, 0.01)\n",
    "                                           )\n",
    "    \n",
    "    # Store chunk outputs in prepared arrays.\n",
    "    out_models[:, start_row:start_row + split_size, :] = models\n",
    "    out_fractions[:, start_row:start_row + split_size, :] = fractions\n",
    "    out_rmse[start_row:start_row + split_size,:] = rmse\n",
    "    out_residuals[:, start_row:start_row + split_size, :] = residuals\n",
    "    out_dicts.append(MESMA.__dict__)\n",
    "    \n",
    "    start_row = start_row + split_size\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    print('Chunk Time: ', stop - start)  \n",
    "    \n",
    "total_stop = timeit.default_timer()\n",
    "print('Total Time: ', total_stop - total_start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d75b1c-2ea7-473d-8425-9f0e11f1ea0d",
   "metadata": {},
   "source": [
    "The chunks are put together to match the spatial shape of the input image and saved to disk using a helper function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3528e-02ba-4b89-99ea-473dcd5d69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_disk(out_models.transpose(0,2,1), \n",
    "            folder_path+img_name, \n",
    "            folder_path+img_name.split('.')[0]+\"_models.tif\")\n",
    "\n",
    "save_to_disk(out_fractions.transpose(0,2,1), \n",
    "            folder_path+\"filepath to file to use profile from\", \n",
    "            folder_path+img_name.split('.')[0]+\"_fractions.tif\")\n",
    "\n",
    "save_to_disk(out_residuals.transpose(0,2,1), \n",
    "            folder_path+\"filepath to file to use profile from\", \n",
    "            folder_path+img_name.split('.')[0]+\"_residuals.tif\")\n",
    "\n",
    "save_to_disk(out_rmse[..., np.newaxis].transpose(2,1,0), \n",
    "            folder_path+\"filepath to file to use profile from\", \n",
    "            folder_path+img_name.split('.')[0]+\"_rmse,tif\")\n",
    "\n",
    "save_to_disk(hard_classification.HardClassification().execute(out_fractions)[..., np.newaxis].transpose(2,1,0), \n",
    "            folder_path+\"filepath to file to use profile from\", \n",
    "            folder_path+img_name.split('.')[0]+\"_classification.tif\")\n",
    "\n",
    "pd.DataFrame(out_dicts).to_csv(folder_path+img_path+img_name.split('.')[0]+\"_params.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
